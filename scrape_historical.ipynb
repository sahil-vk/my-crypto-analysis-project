{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb8eaa-11c2-4e3a-a302-10b26d40fd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996f210c-78fc-46c0-825b-c997dccbfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbe057-00da-4f40-a06c-ad4c9707e79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8987e-58fa-4991-9d2b-3bdec27629fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb9e84-0796-47ae-ac1a-4fa3da000891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0f762d-514e-45f6-81f8-2c17ef95ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleted old file: C:\\Users\\sahil\\OneDrive\\Documents\\Internship\\Final\\Historical\\top_10_crypto_365days_data_2025-04-12_09-27-11.csv\n",
      "üì¢ Fetching historical data (with ATH & ATL) for bitcoin...\n",
      "‚úÖ Data for bitcoin fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for ethereum...\n",
      "‚úÖ Data for ethereum fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for tether...\n",
      "‚úÖ Data for tether fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for ripple...\n",
      "‚úÖ Data for ripple fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for binancecoin...\n",
      "‚úÖ Data for binancecoin fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for solana...\n",
      "‚úÖ Data for solana fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for usd-coin...\n",
      "‚úÖ Data for usd-coin fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for dogecoin...\n",
      "‚úÖ Data for dogecoin fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for tron...\n",
      "‚úÖ Data for tron fetched successfully!\n",
      "\n",
      "üì¢ Fetching historical data (with ATH & ATL) for cardano...\n",
      "‚úÖ Data for cardano fetched successfully!\n",
      "\n",
      "\n",
      "üéâ All data (historical + ATH + ATL) saved successfully to C:\\Users\\sahil\\OneDrive\\Documents\\Internship\\Final\\Historical\\top_10_crypto_365days_data_2025-10-22_00-59-35.csv!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the correct directory for historical data\n",
    "historical_data_dir = r\"C:\\Users\\sahil\\OneDrive\\Documents\\Internship\\Final\\Historical\"\n",
    "\n",
    "# Function to delete old CSV files from the correct directory\n",
    "def delete_old_csv_files():\n",
    "    csv_pattern = os.path.join(historical_data_dir, 'top_10_crypto_365days_data_*.csv')\n",
    "    old_files = glob.glob(csv_pattern)\n",
    "    for file in old_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"üóëÔ∏è Deleted old file: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error deleting {file}: {e}\")\n",
    "\n",
    "delete_old_csv_files()  # Call function to delete old CSV files\n",
    "\n",
    "# Read top 10 coins dynamically from the file\n",
    "with open(r\"C:\\Users\\sahil\\OneDrive\\Documents\\Internship\\Final\\Real time\\top_10_coins.txt\", 'r') as f:\n",
    "    top_10_coins = [line.strip() for line in f.readlines()]\n",
    "\n",
    "currency = 'usd'\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=364)\n",
    "\n",
    "start_timestamp = int(time.mktime(start_date.timetuple()))\n",
    "end_timestamp = int(time.mktime(end_date.timetuple()))\n",
    "\n",
    "# Function to fetch historical data including ATH & ATL with retry mechanism\n",
    "def fetch_coin_data(coin_id, start_timestamp, end_timestamp, currency='usd', max_retries=5):\n",
    "    print(f\"üì¢ Fetching historical data (with ATH & ATL) for {coin_id}...\")\n",
    "    \n",
    "    url = f'https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart/range'\n",
    "    params = {'vs_currency': currency, 'from': start_timestamp, 'to': end_timestamp}\n",
    "    \n",
    "    retry_count = 0\n",
    "    wait_time = 10  # Initial wait time in seconds\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        response = requests.get(url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            prices = data.get('prices', [])\n",
    "            market_caps = data.get('market_caps', [])\n",
    "            total_volumes = data.get('total_volumes', [])\n",
    "            \n",
    "            if prices:\n",
    "                df_prices = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
    "                df_market_caps = pd.DataFrame(market_caps, columns=['timestamp', 'market_cap'])\n",
    "                df_total_volumes = pd.DataFrame(total_volumes, columns=['timestamp', 'total_volume'])\n",
    "                \n",
    "                df = df_prices.merge(df_market_caps, on='timestamp').merge(df_total_volumes, on='timestamp')\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "                df['date'] = df['timestamp'].dt.date\n",
    "                \n",
    "                # Compute OHLC\n",
    "                ohlc = df.groupby('date')['price'].agg(open='first', high='max', low='min', close='last').reset_index()\n",
    "                df = df.merge(ohlc, on='date', how='left').drop(columns=['date'])\n",
    "                \n",
    "                # Fetch ATH & ATL within the same request\n",
    "                url_coin_info = f'https://api.coingecko.com/api/v3/coins/{coin_id}'\n",
    "                response_coin = requests.get(url_coin_info)\n",
    "                \n",
    "                if response_coin.status_code == 200:\n",
    "                    coin_data = response_coin.json()\n",
    "                    ath = coin_data.get('market_data', {}).get('ath', {}).get(currency, None)\n",
    "                    atl = coin_data.get('market_data', {}).get('atl', {}).get(currency, None)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Failed to fetch ATH & ATL for {coin_id}. Error: {response_coin.status_code}\")\n",
    "                    ath, atl = None, None\n",
    "                \n",
    "                # Add ATH & ATL columns\n",
    "                df['ath'] = ath\n",
    "                df['atl'] = atl\n",
    "                \n",
    "                # Insert coin ID column at the beginning\n",
    "                df.insert(0, 'id', coin_id)\n",
    "                \n",
    "                print(f\"‚úÖ Data for {coin_id} fetched successfully!\\n\")\n",
    "                return df\n",
    "            \n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No historical data found for {coin_id}\\n\")\n",
    "                return None\n",
    "        \n",
    "        elif response.status_code == 429:  # Too Many Requests\n",
    "            print(f\"‚è≥ Rate limit hit for {coin_id}. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2  # Exponential backoff\n",
    "            retry_count += 1\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to fetch data for {coin_id}. Error: {response.status_code}\\n\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"üö® Max retries reached for {coin_id}. Skipping...\\n\")\n",
    "    return None\n",
    "\n",
    "# Initialize merged DataFrame\n",
    "merged_df = pd.DataFrame()\n",
    "failed_coins = []\n",
    "\n",
    "# Fetch historical data with ATH & ATL\n",
    "for coin in top_10_coins:\n",
    "    data = fetch_coin_data(coin, start_timestamp, end_timestamp, currency)\n",
    "    if data is not None:\n",
    "        merged_df = pd.concat([merged_df, data], ignore_index=True)\n",
    "    else:\n",
    "        failed_coins.append(coin)\n",
    "    \n",
    "    time.sleep(30)  # ‚úÖ Wait time reduced to 30 seconds\n",
    "\n",
    "# Retry failed coins with backoff\n",
    "if failed_coins:\n",
    "    print(f\"\\nüîÑ Retrying failed coins with backoff: {failed_coins}...\\n\")\n",
    "    for coin in failed_coins:\n",
    "        data = fetch_coin_data(coin, start_timestamp, end_timestamp, currency)\n",
    "        if data is not None:\n",
    "            merged_df = pd.concat([merged_df, data], ignore_index=True)\n",
    "        time.sleep(30)  # ‚úÖ Retry wait time also set to 30 seconds\n",
    "\n",
    "# Define column order\n",
    "column_order = ['id', 'timestamp', 'price', 'market_cap', 'total_volume', 'ath', 'atl', 'open', 'high', 'low', 'close']\n",
    "merged_df = merged_df[column_order]  # Reorder columns\n",
    "\n",
    "# Ensure the directory exists before saving\n",
    "if not os.path.exists(historical_data_dir):\n",
    "    os.makedirs(historical_data_dir)\n",
    "\n",
    "# Save final dataset in the correct directory\n",
    "csv_filename = os.path.join(historical_data_dir, f'top_10_crypto_365days_data_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv')\n",
    "merged_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"\\nüéâ All data (historical + ATH + ATL) saved successfully to {csv_filename}!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d620e5-9a9b-4e8a-bd7d-ae7e43df5782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
